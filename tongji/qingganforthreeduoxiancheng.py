import os
import time
from datetime import datetime
from openpyxl import load_workbook
from collections import Counter
import pandas as pd
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import json
import signal

# åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
# å½“å‰å¯ç”¨ï¼Œå°‘äº†ç¬¬äºŒåˆ—
client = OpenAI(api_key="sk-b56d299a263d4570a59580b1082a262e", base_url="https://api.deepseek.com")

# å…¨å±€å˜é‡
continue_processing = True
lock = threading.Lock()
final_stats = []

import re


def analyze_sentiment(comment):
    """
    ä½¿ç”¨DeepSeek APIåˆ†æè¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼Œå¹¶æå–æ ¸å¿ƒå…³é”®è¯ã€‚
    :param comment: å¾…åˆ†æçš„è¯„è®ºæ–‡æœ¬
    :return: {'sentiment': 'æ­£é¢'/'è´Ÿé¢', 'keywords': ['å…³é”®è¯1', 'å…³é”®è¯2']} æˆ– None
    """
    try:
        start_time = time.time()

        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system",
                 "content": "ä½ æ˜¯ä¸€ä½æ—…æ¸¸è¯„è®ºæƒ…æ„Ÿåˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨è´Ÿè´£åˆ¤æ–­å°çº¢ä¹¦ä¸Šçš„è¯„è®ºæ˜¯æ­£é¢è¿˜æ˜¯è´Ÿé¢ï¼Œå¹¶æå–å‡ºæœ€èƒ½è¡¨è¾¾æƒ…ç»ªçš„å…³é”®è¯ã€‚"},
                {"role": "user", "content": (
                    "è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­ä¸€æ¡æ¥è‡ªå°çº¢ä¹¦çš„è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘å¹¶æå–å…³é”®è¯ï¼š\n\n"
                    "1. å¦‚æœè¯„è®ºè¡¨è¾¾äº†å¯¹æ¸¸è§ˆä½“éªŒçš„å–œçˆ±ã€èµç¾æˆ–æ»¡æ„ï¼Œè¯·è¿”å› 'æ­£é¢' å¹¶æå–æœ€èƒ½ä»£è¡¨è¿™ç§æƒ…æ„Ÿçš„å…³é”®è¯ã€‚\n"
                    "2. å¦‚æœè¯„è®ºè¡¨è¾¾äº†ä¸æ»¡ã€æŠ±æ€¨æˆ–æ‰¹è¯„ï¼Œè¯·è¿”å› 'è´Ÿé¢' å¹¶æå–æœ€èƒ½ä»£è¡¨è¿™ç§æƒ…æ„Ÿçš„å…³é”®è¯ã€‚\n"
                    "3. å…³é”®è¯åº”ç®€æ´æ˜äº†ï¼Œä¾‹å¦‚ï¼šå…è´¹ã€æ–¹ä¾¿ã€å‡†ç‚¹ã€äººå¤šã€æ’é˜Ÿã€è´µç­‰ã€‚\n"
                    "4. ä¸è¦è¿”å›æ•´å¥è¯ï¼Œåªæå–å…³é”®è¯å³å¯ã€‚\n"
                    "5. å¦‚æœè¯„è®ºæåˆ°äº†å¤šä¸ªå…³é”®è¯ï¼Œè¯·æŒ‰é‡è¦æ€§æ’åºï¼Œå–æœ€é‡è¦çš„1~2ä¸ªã€‚\n\n"
                    "è¯·ä»¥ä¸¥æ ¼çš„JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œæ ¼å¼ä¸ºï¼š{'sentiment': 'æ­£é¢/è´Ÿé¢', 'keywords': ['å…³é”®è¯1', 'å…³é”®è¯2']}ã€‚\n"
                    "ä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ï¼Œä¸è¦ä½¿ç”¨Markdownæ ¼å¼ã€‚\n\n"
                    f"ç°åœ¨è¯·åˆ†æä»¥ä¸‹è¯„è®ºï¼š\n{comment}"
                )}
            ],
            stream=False
        )

        content = response.choices[0].message.content.strip()
        print(f"ğŸ§  DeepSeekåŸå§‹è¾“å‡º: {content}")

        # âœ… æ·»åŠ å¤„ç†é€»è¾‘ï¼šå°†å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·ï¼Œå¹¶ä¿®å¤å¯èƒ½çš„è¯­æ³•é—®é¢˜
        content = content.replace("â€œ", '"').replace("â€", '"').replace("â€˜", "'").replace("â€™", "'")
        content = re.sub(r"(?<!\\)'", '"', content)  # å°†æ‰€æœ‰æœªè½¬ä¹‰çš„å•å¼•å·æ›¿æ¢æˆåŒå¼•å·

        result = json.loads(content)

        sentiment = result.get("sentiment")
        keywords = result.get("keywords", [])

        if not isinstance(keywords, list):
            keywords = []

        elapsed = time.time() - start_time
        print(f"ğŸ” åˆ†æè¯„è®º '{comment[:20]}...' çš„æƒ…æ„Ÿå€¾å‘: {sentiment} | æå–å…³é”®è¯: {keywords}ï¼ˆè€—æ—¶ï¼š{elapsed:.2f}sï¼‰")

        if sentiment in ["æ­£é¢", "è´Ÿé¢"] and keywords:
            return {"sentiment": sentiment, "keywords": keywords}
        else:
            return None

    except json.JSONDecodeError as je:
        print(f"âŒ JSONè§£æå¤±è´¥: {je}ï¼ŒåŸå§‹å†…å®¹ä¸ºï¼š'{content}'")
        return None
    except Exception as e:
        print(f"âŒ è°ƒç”¨DeepSeek APIå¤±è´¥: {e}")
        return None


def process_single_element(element, df_comments):
    """
    å•ä¸ªå…³é”®è¯çš„å¤„ç†é€»è¾‘ï¼Œåªæå–å…³é”®è¯
    """
    print(f"ğŸ” å¼€å§‹å¤„ç†å…³é”®è¯: '{element}'")

    filtered_comments = df_comments[df_comments.iloc[:, 0].astype(str).str.contains(element, case=False, na=False)]

    if filtered_comments.empty:
        print(f"âš ï¸ æœªæ‰¾åˆ°å…³é”®è¯ '{element}' åœ¨ç¬¬ä¸€åˆ—çš„ç›¸å…³è¯„è®ºã€‚")
        return None

    pos_keywords = set()
    neg_keywords = set()

    for _, row in filtered_comments.iterrows():
        if not continue_processing:
            break

        comment = str(row.iloc[0]).strip()
        result = analyze_sentiment(comment)

        if result:
            sentiment = result["sentiment"]
            keywords = result["keywords"]

            if sentiment == "æ­£é¢":
                pos_keywords.update(keywords)
                if len(pos_keywords) >= 5:
                    pos_keywords = set(list(pos_keywords)[:5])
            elif sentiment == "è´Ÿé¢":
                neg_keywords.update(keywords)
                if len(neg_keywords) >= 5:
                    neg_keywords = set(list(neg_keywords)[:5])

    top_pos = ", ".join(pos_keywords) if pos_keywords else ""
    top_neg = ", ".join(neg_keywords) if neg_keywords else ""

    if top_pos or top_neg:
        result = {
            "æ—…æ¸¸è¦ç´ ": element,
            "ä¸»è¦æ­£é¢æè¿°è¯": top_pos,
            "ä¸»è¦è´Ÿé¢æè¿°è¯": top_neg
        }
        print(f"ğŸ“Š å…³é”®è¯ '{element}' ç»Ÿè®¡å®Œæˆï¼š")
        print(f"   â• æ­£é¢æè¿°è¯ï¼š{top_pos}")
        print(f"   â– è´Ÿé¢æè¿°è¯ï¼š{top_neg}")
        return result
    else:
        print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºè¡Œï¼šå…³é”®è¯ '{element}' çš„ä¸»è¦æ­£/è´Ÿé¢æè¿°è¯å‡ä¸ºç©ºã€‚")
        return None


def extract_red_keywords(file_path):
    """
    æå–æŒ‡å®šExcelæ–‡ä»¶ç¬¬ä¸€ä¸ªSheeté¡µä¸­æ‰€æœ‰çº¢è‰²å­—ä½“çš„å•å…ƒæ ¼å†…å®¹ã€‚
    :param file_path: Excelæ–‡ä»¶è·¯å¾„
    :return: çº¢è‰²å…³é”®è¯åˆ—è¡¨
    """
    red_keywords = []

    try:
        wb = load_workbook(file_path)
        ws = wb.active

        for row in ws.iter_rows():
            for cell in row:
                if cell.font and cell.font.color:
                    color = cell.font.color.rgb
                    if color in ['FFFF0000', 'FF0000']:
                        if cell.value:
                            value = str(cell.value).strip()
                            red_keywords.append(value)
                            print(f"ğŸ”´ æå–åˆ°çº¢è‰²å…³é”®è¯: '{value}'")
        print(f"âœ… æˆåŠŸæå–åˆ° {len(red_keywords)} ä¸ªçº¢è‰²å…³é”®è¯ã€‚")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

    return red_keywords


def signal_handler(sig, frame):
    global continue_processing
    print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ä¿¡å·æ•è· (Ctrl+C)ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
    continue_processing = False


def main():
    global continue_processing

    start_time = time.time()
    print(f"ğŸ•’ ç¨‹åºå¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    current_dir = os.path.dirname(os.path.abspath(__file__))
    input_folder = os.path.join(current_dir, '..', 'qingganqingxiang')
    output_folder = os.path.join(current_dir, '..', 'outputfile')

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    red_file = None
    comments_file = None

    for f in os.listdir(input_folder):
        if f.startswith("1_") and f.endswith(".xlsx"):
            red_file = f
        elif f.startswith("3_") and f.endswith(".xlsx"):
            comments_file = f

    if not red_file:
        print("âŒ æœªæ‰¾åˆ°ä»¥ '1_' å¼€å¤´çš„çº¢è‰²å…³é”®è¯æå–æ–‡ä»¶ã€‚")
        return
    if not comments_file:
        print("âŒ æœªæ‰¾åˆ°ä»¥ '3_' å¼€å¤´çš„è¯„è®ºæ–‡ä»¶ã€‚")
        return

    file1_path = os.path.join(input_folder, red_file)
    file3_path = os.path.join(input_folder, comments_file)

    print(f"\nğŸ“„ ä½¿ç”¨æ–‡ä»¶æå–çº¢è‰²å…³é”®è¯: {red_file}")
    print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶ä½œä¸ºè¯„è®ºæ¥æº: {comments_file}")

    red_elements = extract_red_keywords(file1_path)
    if not red_elements:
        print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•çº¢è‰²å…³é”®è¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼æˆ–é¢œè‰²è®¾ç½®ã€‚")
        return

    try:
        df_comments = pd.read_excel(file3_path, sheet_name=0)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–è¯„è®ºæ•°æ®æ–‡ä»¶: {e}")
        return

    unique_elements = set(red_elements)
    print(f"ğŸ”¢ å…±è¯†åˆ«åˆ° {len(unique_elements)} ä¸ªå”¯ä¸€æ—…æ¸¸è¦ç´ ï¼š{unique_elements}")

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = []
        for element in unique_elements:
            if not continue_processing:
                break
            future = executor.submit(process_single_element, element, df_comments)
            futures.append(future)

        for future in as_completed(futures):
            if not continue_processing:
                break
            result = future.result()
            if result:
                with lock:
                    final_stats.append(result)

    if final_stats:
        result_df = pd.DataFrame(final_stats, columns=[
            "æ—…æ¸¸è¦ç´ ", "ä¸»è¦æ­£é¢æè¿°è¯", "ä¸»è¦è´Ÿé¢æè¿°è¯"
        ])

        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
        output_file = os.path.join(output_folder, f"statistics_output_{timestamp}.xlsx")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶è·¯å¾„: {output_file}")

        try:
            result_df.to_excel(output_file, index=False, engine='openpyxl')
            print(f"âœ… ç»Ÿè®¡ç»“æœå·²æˆåŠŸä¿å­˜è‡³: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
    else:
        print("âš ï¸ æ²¡æœ‰å®Œæ•´çš„ç»Ÿè®¡æ•°æ®å¯è¾“å‡ºã€‚")

    total_elapsed = time.time() - start_time
    print(f"ğŸ ç¨‹åºç»“æŸï¼Œæ€»è€—æ—¶ï¼š{total_elapsed:.2f} ç§’")


if __name__ == '__main__':
    main()
